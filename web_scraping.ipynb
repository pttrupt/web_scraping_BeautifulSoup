{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "67e6c91e-20dc-44e1-b333-0fd449274413",
      "metadata": {
        "id": "67e6c91e-20dc-44e1-b333-0fd449274413"
      },
      "source": [
        "### Outline Project \n",
        "\n",
        "* Site is https://www.cars24.com\n",
        "* Get the list of cities names. For each city, get city title, city page URL \n",
        "* For each city, get the top 20 used cars url from each pages \n",
        "* For each car, we'll take \n",
        "    - car name, brand name, history, kms driven\n",
        "    - registartion, year of purchase, owner, fuel\n",
        "    - transmission, insurance\n",
        "* For each city, create CSV file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2edda2a-43ac-43d3-b24e-7772bc3f357f",
      "metadata": {
        "id": "e2edda2a-43ac-43d3-b24e-7772bc3f357f"
      },
      "source": [
        "#### import libraries for scraping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "030f2312-936f-4ee3-8b13-d109d1294caf",
      "metadata": {
        "id": "030f2312-936f-4ee3-8b13-d109d1294caf"
      },
      "outputs": [],
      "source": [
        "!pip install requests bs4 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "f15750a0-d782-43c6-85fe-601f3892f4ca",
      "metadata": {
        "id": "f15750a0-d782-43c6-85fe-601f3892f4ca"
      },
      "outputs": [],
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b892a4-432b-4d2e-9134-15cfac4705b2",
      "metadata": {
        "id": "57b892a4-432b-4d2e-9134-15cfac4705b2"
      },
      "source": [
        "#### Downloadinf Web Page with `requests.get()` function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "id": "18a30094-0ba8-4b6a-aa2a-aecfcf3fef98",
      "metadata": {
        "id": "18a30094-0ba8-4b6a-aa2a-aecfcf3fef98"
      },
      "outputs": [],
      "source": [
        "# hard coding Cities name in list \n",
        "\n",
        "cities = [\"New delhi\", \"noida\", \"gurgaon\", \"pune\",\n",
        "         \"bengaluru\", \"hyderabad\", \"chennai\", \"kolkata\",\n",
        "         \"Ahmedabad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "0e9e4980-7ee9-4559-bbaf-80f41236961a",
      "metadata": {
        "id": "0e9e4980-7ee9-4559-bbaf-80f41236961a"
      },
      "outputs": [],
      "source": [
        "def gather_cities_url(cities, pages = 5):\n",
        "    ''' return dictionary which contains key as cities name and \n",
        "        values as cities url no of `pages`'''\n",
        "    \n",
        "    # will contain each cities name as key and \n",
        "    # values as cities url for each page\n",
        "    cities_dict = {} \n",
        "    \n",
        "    for city in cities:\n",
        "        # trimming whitespaces, replacing string spaces with '-'\n",
        "        # converting into lowercase \n",
        "        city = city.strip().replace(\" \", \"-\").lower()\n",
        "        \n",
        "        # contains each page URL's of city \n",
        "        city_URL = []\n",
        "        for page in range(1,pages+1):\n",
        "            URL = f\"https://www.cars24.com/buy-used-cars-{city}/?page={page}\"\n",
        "            city_URL.append(URL)\n",
        "        \n",
        "        # storing city name as key and\n",
        "        # city pages url's as values into cities_dict \n",
        "        cities_dict[city]= city_URL\n",
        "        \n",
        "    return cities_dict        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "7650b9b7-cbaa-435c-b4e4-1231ec79e93a",
      "metadata": {
        "id": "7650b9b7-cbaa-435c-b4e4-1231ec79e93a"
      },
      "outputs": [],
      "source": [
        "def get_city_requests(city_name, cities_url_):\n",
        "    ''' Returns list of responses for each url in citi_url \n",
        "        corresponding to city_name '''\n",
        "    # city_name (string) should be into cities_url otherwise thrown an ERROR.\n",
        "    # cities_url (dictionary) contains url's for each page as value and for each city as key \n",
        "    \n",
        "    cityName = city_name.strip().replace(\" \",\"-\").lower()\n",
        "    \n",
        "    # make sure city_name is in cities_url \n",
        "    if cityName not in cities_url_:\n",
        "        return f\"Incorrect city name. '{city_name}' city is not in cities_url.\"\n",
        "    \n",
        "    requests_url = [requests.get(page_url) for page_url in cities_url_[cityName]]\n",
        "    \n",
        "    return requests_url "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "4c5354ed-d1a7-4741-9aa4-ea6fb626fba6",
      "metadata": {
        "id": "4c5354ed-d1a7-4741-9aa4-ea6fb626fba6"
      },
      "outputs": [],
      "source": [
        "def city_bs4_object(city_name, citiesUrl):\n",
        "    ''' Function uses `get_city_requests` function and create \n",
        "    BeautifulSoup object from 'get_city_requests` result '''\n",
        "    # city_name (string) should be into cities_url otherwise thrown an ERROR.\n",
        "    # cities_url (dictionary) contains url's for each page as value and for each city as key\n",
        "        \n",
        "    request_url = get_city_requests(city_name, citiesUrl)\n",
        "    \n",
        "    Beautiful_obj = [BeautifulSoup(each_page_url.text, 'lxml')\n",
        "                                   for each_page_url in request_url]\n",
        "    return Beautiful_obj "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "id": "d32c26f5-8fe6-4528-bd74-33fa22c8bca0",
      "metadata": {
        "id": "d32c26f5-8fe6-4528-bd74-33fa22c8bca0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def car_page_link(city_BS_Object):\n",
        "    '''Returns list of BeautifulSoup Object for every cars in each page '''\n",
        "        \n",
        "    # finding all the car objects in doc \n",
        "    car_doc = [cityObject.find_all('a', class_='_9Ue0B') for cityObject in city_BS_Object]\n",
        "    \n",
        "    # collecting each car objects URL \n",
        "    car_URL = [i['href'] for each_page in car_doc for i in each_page]\n",
        "    \n",
        "    requests_ = [requests.get(j) for j in car_URL]\n",
        "\n",
        "    # get html page of each car object Url and parsing with BeautifulSoup\n",
        "    car_res = [BeautifulSoup(req.text, 'lxml') for req in requests_]\n",
        "    \n",
        "    return car_res "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "id": "01018207-c760-40bf-bb66-8dd883fb30e2",
      "metadata": {
        "id": "01018207-c760-40bf-bb66-8dd883fb30e2"
      },
      "outputs": [],
      "source": [
        "def car_specification(car_res):\n",
        "    \n",
        "    '''Returns Dictionary containing the scrapped informations like\n",
        "       - Car Model\n",
        "       - Price\n",
        "       - History etc...\n",
        "    '''\n",
        "        \n",
        "    dataset = {\n",
        "               \"Car Model\":[], \n",
        "               \"Price\":[], \n",
        "               \"History\":[], \n",
        "               \"Kilometers Driven\":[],\n",
        "               \"Transmission\":[], \n",
        "               \"Insurance\": [],\n",
        "               \"Owner\":[],\n",
        "               \"Fuel Type\":[], \n",
        "               \"Registration\":[],\n",
        "               \"Year of Purchase\":[],\n",
        "               \"Last Service\":[]\n",
        "               } \n",
        "    \n",
        "    for car_num, each_car in enumerate(car_res):\n",
        "        car_price = each_car.find('strong', class_='_2yYvS')\n",
        "        car_model = each_car.find('h2', class_='_2geSF')\n",
        "        if not car_price or not car_model:\n",
        "          continue \n",
        "        car_price = car_price.text.split('â‚¹')[-1]\n",
        "        car_model = car_model.text\n",
        "        \n",
        "\n",
        "        dataset[\"Price\"].append(car_price)\n",
        "        dataset[\"Car Model\"].append(car_model)\n",
        "\n",
        "        columns = [ \"History\", \"Kilometers Driven\",\"Transmission\",\"Insurance\",\n",
        "                   \"Owner\",\"Fuel Type\", \"Registration\",\"Year of Purchase\",\n",
        "                   \"Last Service\"]\n",
        "\n",
        "        car_feature = []\n",
        "\n",
        "        car_col_val = each_car.find_all('li', class_='tHlIu')\n",
        "\n",
        "        for each_tag in car_col_val:\n",
        "          feature = each_tag.find('label', class_='_1Q_nE').text.strip()\n",
        "          feature_spec = each_tag.find_all('strong', class_='_1-PH2')[0].text.strip()\n",
        "\n",
        "          car_feature.append(feature)\n",
        "          dataset[feature].append(feature_spec)\n",
        "\n",
        "        for column in columns:\n",
        "          if column not in car_feature:\n",
        "            dataset[column].append(None)\n",
        "\n",
        "    return dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "17d509ea-06c8-4699-83be-2d0b778e2485",
      "metadata": {
        "id": "17d509ea-06c8-4699-83be-2d0b778e2485"
      },
      "outputs": [],
      "source": [
        "cities_urls = gather_cities_url(cities, pages=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "0e563006-f285-49a0-a048-8cfc3d605c48",
      "metadata": {
        "id": "0e563006-f285-49a0-a048-8cfc3d605c48"
      },
      "outputs": [],
      "source": [
        "city_soup = city_bs4_object('kolkata', cities_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "id": "b540cf0d-106d-48e8-9de9-381bc4db2628",
      "metadata": {
        "id": "b540cf0d-106d-48e8-9de9-381bc4db2628"
      },
      "outputs": [],
      "source": [
        "abd_car_pages = car_page_link(city_soup)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(car_pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo6NNHvNU4d0",
        "outputId": "75476c36-e9de-47c4-9083-b1091f4b8f00"
      },
      "id": "Fo6NNHvNU4d0",
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = car_specification(abd_car_pages)"
      ],
      "metadata": {
        "id": "ssSmKRQokH6e"
      },
      "id": "ssSmKRQokH6e",
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "65ab3b4f-aff1-460b-9da3-2686f00118f6",
      "metadata": {
        "id": "65ab3b4f-aff1-460b-9da3-2686f00118f6"
      },
      "source": [
        "#### Converting dictionaries into DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "id": "2d1087d7-5137-4274-a55d-cb07a9f96104",
      "metadata": {
        "id": "2d1087d7-5137-4274-a55d-cb07a9f96104"
      },
      "outputs": [],
      "source": [
        "import pandas as pd "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "id": "b95d01c5-7617-42d9-8300-b0ca9af0cb98",
      "metadata": {
        "id": "b95d01c5-7617-42d9-8300-b0ca9af0cb98"
      },
      "outputs": [],
      "source": [
        "df_sample = pd.DataFrame(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "id": "7d3fde4b-9b0a-4562-b5be-6612709f0dc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d3fde4b-9b0a-4562-b5be-6612709f0dc6",
        "outputId": "3ec52816-3ec8-4d85-fc25-cf68a4bf76c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(285, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ],
      "source": [
        "df_sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "id": "c964d2d8-5263-48de-b277-900f0bb6189d",
      "metadata": {
        "id": "c964d2d8-5263-48de-b277-900f0bb6189d"
      },
      "outputs": [],
      "source": [
        "df_sample.to_csv(\"Kolkata.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "colab": {
      "name": "web_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}